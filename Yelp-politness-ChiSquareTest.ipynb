{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob, Word, Blobber\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from textblob.taggers import NLTKTagger\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textstat\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.linear_model import Ridge\n",
    "import datetime as dt\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_review=\"D:/Trinity_DS/Dissertations/201907/politness/politness_predicted/yelp_polite.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = pd.read_csv(path_review,low_memory=False,encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>politness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ymAUG8DZfQcFTBSOiaNN4w</td>\n",
       "      <td>u0LXt3Uea_GidxRW1xcsfg</td>\n",
       "      <td>9_CGhHMz8698M9-PkVf0CQ</td>\n",
       "      <td>4</td>\n",
       "      <td>5/11/2012</td>\n",
       "      <td>Who would have guess that you would be able to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.067161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w41ZS9shepfO3uEyhXEWuQ</td>\n",
       "      <td>u0LXt3Uea_GidxRW1xcsfg</td>\n",
       "      <td>5r6-G9C4YLbC7Ziz57l3rQ</td>\n",
       "      <td>3</td>\n",
       "      <td>2/9/2013</td>\n",
       "      <td>Not bad!! Love that there is a gluten-free, ve...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIsUSmvaUWB00qv5KTF1xA</td>\n",
       "      <td>u0LXt3Uea_GidxRW1xcsfg</td>\n",
       "      <td>z8oIoCT1cXz7gZP5GeU5OA</td>\n",
       "      <td>4</td>\n",
       "      <td>5/1/2013</td>\n",
       "      <td>This is currently my parents new favourite res...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.531268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PdZ_uFjbbkjtm3SCY_KrZw</td>\n",
       "      <td>u0LXt3Uea_GidxRW1xcsfg</td>\n",
       "      <td>XWTPNfskXoUL-Lf32wSk0Q</td>\n",
       "      <td>3</td>\n",
       "      <td>9/28/2011</td>\n",
       "      <td>Server was a little rude.\\r\\n\\r\\nOrdered the c...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.053217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsoSqIrrDbQvWpMvsSj2xw</td>\n",
       "      <td>u0LXt3Uea_GidxRW1xcsfg</td>\n",
       "      <td>RtUvSWO_UZ8V3Wpj0n077w</td>\n",
       "      <td>3</td>\n",
       "      <td>12/3/2012</td>\n",
       "      <td>Wanted to check out this place due to all the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.157010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  ymAUG8DZfQcFTBSOiaNN4w  u0LXt3Uea_GidxRW1xcsfg  9_CGhHMz8698M9-PkVf0CQ   \n",
       "1  w41ZS9shepfO3uEyhXEWuQ  u0LXt3Uea_GidxRW1xcsfg  5r6-G9C4YLbC7Ziz57l3rQ   \n",
       "2  PIsUSmvaUWB00qv5KTF1xA  u0LXt3Uea_GidxRW1xcsfg  z8oIoCT1cXz7gZP5GeU5OA   \n",
       "3  PdZ_uFjbbkjtm3SCY_KrZw  u0LXt3Uea_GidxRW1xcsfg  XWTPNfskXoUL-Lf32wSk0Q   \n",
       "4  lsoSqIrrDbQvWpMvsSj2xw  u0LXt3Uea_GidxRW1xcsfg  RtUvSWO_UZ8V3Wpj0n077w   \n",
       "\n",
       "   stars       date                                               text  \\\n",
       "0      4  5/11/2012  Who would have guess that you would be able to...   \n",
       "1      3   2/9/2013  Not bad!! Love that there is a gluten-free, ve...   \n",
       "2      4   5/1/2013  This is currently my parents new favourite res...   \n",
       "3      3  9/28/2011  Server was a little rude.\\r\\n\\r\\nOrdered the c...   \n",
       "4      3  12/3/2012  Wanted to check out this place due to all the ...   \n",
       "\n",
       "   useful  funny  cool  politness  \n",
       "0       0      0     2   0.067161  \n",
       "1       1      0     0   0.045530  \n",
       "2       1      0     0  -0.531268  \n",
       "3       5      0     1  -0.053217  \n",
       "4       2      1     1  -0.157010  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review=df_review.drop(df_review.columns[0], axis=1)\n",
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.DataFrame()\n",
    "df_review['date'] =  pd.to_datetime(df_review['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['day_of_week'] = df_review['date'].dt.weekday_name\n",
    "analysis_df['stars'] = df_review['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 5, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df.stars.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ratings</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Days</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Friday</th>\n",
       "      <td>1979</td>\n",
       "      <td>2141</td>\n",
       "      <td>3783</td>\n",
       "      <td>6778</td>\n",
       "      <td>5881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monday</th>\n",
       "      <td>2273</td>\n",
       "      <td>2644</td>\n",
       "      <td>4626</td>\n",
       "      <td>8125</td>\n",
       "      <td>6581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saturday</th>\n",
       "      <td>2276</td>\n",
       "      <td>2526</td>\n",
       "      <td>4035</td>\n",
       "      <td>7164</td>\n",
       "      <td>6564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunday</th>\n",
       "      <td>2678</td>\n",
       "      <td>2739</td>\n",
       "      <td>4698</td>\n",
       "      <td>8233</td>\n",
       "      <td>7046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thursday</th>\n",
       "      <td>1780</td>\n",
       "      <td>2246</td>\n",
       "      <td>3769</td>\n",
       "      <td>6621</td>\n",
       "      <td>5580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuesday</th>\n",
       "      <td>1825</td>\n",
       "      <td>2251</td>\n",
       "      <td>3974</td>\n",
       "      <td>7249</td>\n",
       "      <td>5619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wednesday</th>\n",
       "      <td>1879</td>\n",
       "      <td>2302</td>\n",
       "      <td>4075</td>\n",
       "      <td>7339</td>\n",
       "      <td>6021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ratings       1     2     3     4     5\n",
       "Days                                   \n",
       "Friday     1979  2141  3783  6778  5881\n",
       "Monday     2273  2644  4626  8125  6581\n",
       "Saturday   2276  2526  4035  7164  6564\n",
       "Sunday     2678  2739  4698  8233  7046\n",
       "Thursday   1780  2246  3769  6621  5580\n",
       "Tuesday    1825  2251  3974  7249  5619\n",
       "Wednesday  1879  2302  4075  7339  6021"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_matix= np.array(analysis_df)\n",
    "np_matix\n",
    "days_rating=pd.crosstab(np_matix[:,0],np_matix[:,1],\n",
    "            rownames=['Days'], colnames=['Ratings'],)\n",
    "chi2 , p ,dof ,expected = stats.chi2_contingency(days_rating)\n",
    "days_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews and DaysOfWeek chi_2 value--------------- 161.90234724872974\n",
      "Reviews and DaysOfWeek p value------------------- 1.9730334914915967e-22\n",
      "Reviews and DaysOfWeek degreeoffreedom value----- 24\n"
     ]
    }
   ],
   "source": [
    "days_rating=pd.crosstab(np_matix[:,0],np_matix[:,1],\n",
    "            rownames=['Days'], colnames=['Ratings'],)\n",
    "chi2 , p ,dof ,expected = stats.chi2_contingency(days_rating)\n",
    "print(\"Reviews and DaysOfWeek chi_2 value---------------\",chi2)\n",
    "print(\"Reviews and DaysOfWeek p value-------------------\",p)\n",
    "print(\"Reviews and DaysOfWeek degreeoffreedom value-----\",dof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependent (reject H0)\n",
      "Reviews Dependent on Days of the Week\n",
      "significance=0.050, p=0.000\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "prob=0.95    \n",
    "critical_day = stats.chi2.ppf(prob, dof)\n",
    "if abs(chi2) >= critical_day:\n",
    "    print('Dependent (reject H0)')\n",
    "    print('Reviews Dependent on Days of the Week')\n",
    "else:\n",
    "    print('Independent (fail to reject H0)')\n",
    "alpha = 1.0 - prob\n",
    "print('significance=%.3f, p=%.3f' % (alpha, p))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (fail to reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>stars</th>\n",
       "      <th>Weekend_WeekDays</th>\n",
       "      <th>high_low_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Friday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>3</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>3</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Friday</td>\n",
       "      <td>5</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>3</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>3</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Friday</td>\n",
       "      <td>3</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>3</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Monday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Friday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Monday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155270</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>5</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155271</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155272</th>\n",
       "      <td>Friday</td>\n",
       "      <td>5</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155273</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155274</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155275</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155276</th>\n",
       "      <td>Friday</td>\n",
       "      <td>2</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155277</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155278</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>5</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155279</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155280</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155281</th>\n",
       "      <td>Friday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155282</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>3</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155283</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155284</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>5</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155285</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155286</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155287</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155288</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>5</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155289</th>\n",
       "      <td>Monday</td>\n",
       "      <td>5</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155290</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155291</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155292</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155293</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155294</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>3</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155295</th>\n",
       "      <td>Monday</td>\n",
       "      <td>2</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155296</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155297</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>2</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155298</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155299</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>3</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155300 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       day_of_week  stars Weekend_WeekDays high_low_Rating\n",
       "0           Friday      4          Weekday            high\n",
       "1         Saturday      3          Weekend             low\n",
       "2        Wednesday      4          Weekday            high\n",
       "3        Wednesday      3          Weekday             low\n",
       "4           Monday      3          Weekday             low\n",
       "5           Friday      5          Weekday            high\n",
       "6        Wednesday      3          Weekday             low\n",
       "7           Sunday      3          Weekend             low\n",
       "8          Tuesday      1          Weekday             low\n",
       "9           Friday      3          Weekday             low\n",
       "10          Monday      3          Weekday             low\n",
       "11        Thursday      1          Weekday             low\n",
       "12          Monday      3          Weekday             low\n",
       "13          Sunday      3          Weekend             low\n",
       "14          Monday      4          Weekday            high\n",
       "15        Saturday      4          Weekend            high\n",
       "16          Friday      4          Weekday            high\n",
       "17       Wednesday      4          Weekday            high\n",
       "18       Wednesday      4          Weekday            high\n",
       "19        Thursday      4          Weekday            high\n",
       "20       Wednesday      2          Weekday             low\n",
       "21         Tuesday      1          Weekday             low\n",
       "22          Sunday      4          Weekend            high\n",
       "23        Thursday      4          Weekday            high\n",
       "24          Monday      4          Weekday            high\n",
       "25         Tuesday      4          Weekday            high\n",
       "26       Wednesday      2          Weekday             low\n",
       "27          Monday      3          Weekday             low\n",
       "28       Wednesday      4          Weekday            high\n",
       "29       Wednesday      4          Weekday            high\n",
       "...            ...    ...              ...             ...\n",
       "155270    Saturday      5          Weekend            high\n",
       "155271      Sunday      4          Weekend            high\n",
       "155272      Friday      5          Weekday            high\n",
       "155273   Wednesday      5          Weekday            high\n",
       "155274   Wednesday      5          Weekday            high\n",
       "155275   Wednesday      4          Weekday            high\n",
       "155276      Friday      2          Weekday             low\n",
       "155277   Wednesday      5          Weekday            high\n",
       "155278    Thursday      5          Weekday            high\n",
       "155279     Tuesday      4          Weekday            high\n",
       "155280   Wednesday      5          Weekday            high\n",
       "155281      Friday      4          Weekday            high\n",
       "155282   Wednesday      3          Weekday             low\n",
       "155283   Wednesday      4          Weekday            high\n",
       "155284     Tuesday      5          Weekday            high\n",
       "155285      Sunday      4          Weekend            high\n",
       "155286     Tuesday      2          Weekday             low\n",
       "155287   Wednesday      5          Weekday            high\n",
       "155288     Tuesday      5          Weekday            high\n",
       "155289      Monday      5          Weekday            high\n",
       "155290    Thursday      1          Weekday             low\n",
       "155291     Tuesday      4          Weekday            high\n",
       "155292    Thursday      4          Weekday            high\n",
       "155293     Tuesday      2          Weekday             low\n",
       "155294    Saturday      3          Weekend             low\n",
       "155295      Monday      2          Weekday             low\n",
       "155296    Saturday      4          Weekend            high\n",
       "155297    Saturday      2          Weekend             low\n",
       "155298     Tuesday      2          Weekday             low\n",
       "155299    Saturday      3          Weekend             low\n",
       "\n",
       "[155300 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df=analysis_df\n",
    "transformed_df['Weekend_WeekDays'] = np.where((transformed_df['day_of_week']=='Sunday') | (transformed_df['day_of_week']=='Saturday'),\n",
    "                                              'Weekend','Weekday')\n",
    "transformed_df['high_low_Rating'] = np.where(transformed_df['stars']<=3,\n",
    "                                              'low','high')\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>WeekendWeekdays</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Weekend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_low_Rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>65794</td>\n",
       "      <td>29007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>41547</td>\n",
       "      <td>18952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "WeekendWeekdays  Weekday  Weekend\n",
       "high_low_Rating                  \n",
       "high               65794    29007\n",
       "low                41547    18952"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformedMatrix= np.array(transformed_df)\n",
    "crWeekendWeekdays=pd.crosstab(transformedMatrix[:,3],transformedMatrix[:,2],\n",
    "            rownames=['high_low_Rating'], colnames=['WeekendWeekdays'])\n",
    "crWeekendWeekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HighLowRating and WeekendWeekdays chi_2 value--------------- 9.144751181089555\n",
      "HighLowRating and WeekendWeekdays p value------------------- 0.002494325563510335\n",
      "HighLowRating and WeekendWeekdays degreeoffreedom value----- 1\n",
      "Dependent (reject H0) Hypothesis tested with probability of 95% and alpha of 0.5\n",
      "High Low Ratings Dependent on Six hours bands\n",
      "Dependent (reject H0) Hypothesis tested with probability of 95% and alpha of 0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chi2_v4 , p_v4  ,dof_v4  ,expected_v4  = stats.chi2_contingency(crWeekendWeekdays)\n",
    "print(\"HighLowRating and WeekendWeekdays chi_2 value---------------\",chi2_v4)\n",
    "print(\"HighLowRating and WeekendWeekdays p value-------------------\",p_v4)\n",
    "print(\"HighLowRating and WeekendWeekdays degreeoffreedom value-----\",dof_v4)\n",
    "prob=0.95\n",
    "critical_hour = stats.chi2.ppf(prob, dof_v4)\n",
    "if abs(chi2_v4) >= critical_hour:\n",
    "    print('Dependent (reject H0) Hypothesis tested with probability of 95% and alpha of 0.5')\n",
    "    print('High Low Ratings Dependent on Six hours bands')\n",
    "else:\n",
    "    print('Independent (fail to reject H0) Hypothesis tested with probability of 95% and alpha of 0.5')\n",
    "if p_v4 <= alpha:\n",
    "    print('Dependent (reject H0) Hypothesis tested with probability of 95% and alpha of 0.5')\n",
    "else:\n",
    "    print('Independent (fail to reject H0) Hypothesis tested with probability of 95% and alpha of 0.5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(analysis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#textstat.flesch_reading_ease(.id)\n",
    "readablity = []\n",
    "for text in df_review['text']:\n",
    "    readablity.append(textstat.flesch_reading_ease((text)))\n",
    "analysis_df['flesch_reading_ease']=readablity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df= df_review[['stars','useful']]\n",
    "df_review.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smog = []\n",
    "for text in df_review['text']:\n",
    "    smog.append(textstat.smog_index(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coleman_liau=[]\n",
    "for text in df_review['text']:\n",
    "    coleman_liau.append(textstat.coleman_liau_index(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_count=[]\n",
    "for text in df_review['text']:\n",
    "    sentence_count.append(textstat.sentence_count(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gunning_fog=[]\n",
    "for text in df_review['text']:\n",
    "    gunning_fog.append(textstat.gunning_fog(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flesch_kincaid_grade=[]\n",
    "for text in df_review['text']:\n",
    "    flesch_kincaid_grade.append(textstat.flesch_kincaid_grade(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectivity_list=[]\n",
    "polarity_list=[]\n",
    "for text in df_review['text']:\n",
    "    subjectivity_list.append(TextBlob(text).sentiment.subjectivity)\n",
    "    polarity_list.append(TextBlob(text).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()\n",
    "spelling_errors=[]\n",
    "\n",
    "for text in df_review['text']:\n",
    "    spelling_errors.append(len(spell.unknown(str(text).split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['smog']=smog\n",
    "analysis_df['coleman_liau']=coleman_liau\n",
    "analysis_df['sentence_count']=sentence_count\n",
    "analysis_df['gunning_fog']=gunning_fog\n",
    "analysis_df['flesch_kincaid_grade']=flesch_kincaid_grade\n",
    "analysis_df['subjectivity']=subjectivity_list\n",
    "analysis_df['polarity']=polarity_list\n",
    "analysis_df['spelling_errors']=spelling_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis_df=analysis_df.drop(analysis_df.columns[8], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['stars']=df_review['stars']\n",
    "analysis_df['useful']=df_review['useful']\n",
    "analysis_df['agg']=df_review['useful']+df_review['funny']+df_review['cool']\n",
    "analysis_df['politness']=df_review['politness']\n",
    "analysis_df['usefull_bin'] = np.where(analysis_df['useful']==0, '0', '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['stars']=df_review['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis_df.dtypes\n",
    "analysis_df.groupby('usefull_bin').count()\n",
    "#analysis_df.to_csv(\"D:/Trinity_DS/Dissertations/201907/yelp/analysis.csv\",index=False)\n",
    "#analysis_df.groupby('usefull_bin').mean()\n",
    "#analysis_df.groupby('usefull_bin').var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.array(analysis_df.drop(['usefull_bin','agg','useful'], axis=1))\n",
    "#X= np.array(analysis_df['smog'])\n",
    "Y= np.array(analysis_df['usefull_bin'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.33, random_state=303)\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "X_test_scaled = preprocessing.scale(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train_scaled, y_train)\n",
    "Y_train_Pred=clf.predict(X_train_scaled)\n",
    "accuracy_score(y_train, Y_train_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_test_Pred=clf.predict(X_test_scaled)\n",
    "target_names = ['0', '1']\n",
    "print(classification_report(y_test, Y_test_Pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(analysis_df)\n",
    "list(analysis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(analysis_df)\n",
    "X= np.array(analysis_df.drop(['usefull_bin','agg','useful','date','usefull_diff','flesch_kincaid_grade','subjectivity'], axis=1))\n",
    "#X= np.array(analysis_df['smog'])\n",
    "Y= np.array(analysis_df['usefull_bin'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.33, random_state=303)\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "X_test_scaled = preprocessing.scale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVM = SVC(gamma='auto',kernel='rbf',C=10)\n",
    "clf_SVM.fit(X_train_scaled, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_Pred=clf_SVM.predict(X_train_scaled)\n",
    "accuracy_score(y_train, Y_train_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_SVM_Pred=clf_SVM.predict(X_test_scaled)\n",
    "Y_test_SVM_Pred\n",
    "target_names=['0','1']\n",
    "print(classification_report(y_test, Y_test_SVM_Pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RF = RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "clf_RF.fit(X_train_scaled, y_train)\n",
    "Y_train_Pred=clf_RF.predict(X_train_scaled)\n",
    "Y_test_RF_Pred=clf_RF.predict(X_test_scaled)\n",
    "print(\"Training Accuracy\",accuracy_score(y_train, Y_train_Pred))\n",
    "target_names=['0','1']\n",
    "print(classification_report(y_test, Y_test_RF_Pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RF = RandomForestClassifier(n_estimators=1000,random_state=0,max_depth=4)\n",
    "clf_RF.fit(X_train_scaled, y_train)\n",
    "Y_train_Pred=clf_RF.predict(X_train_scaled)\n",
    "Y_test_RF_Pred=clf_RF.predict(X_test_scaled)\n",
    "print(\"Training Accuracy\",accuracy_score(y_train, Y_train_Pred))\n",
    "target_names=['0','1']\n",
    "print(classification_report(y_test, Y_test_RF_Pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RF = RandomForestClassifier(n_estimators=2000,random_state=0)\n",
    "clf_RF.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_Pred=clf_RF.predict(X_train_scaled)\n",
    "accuracy_score(y_train, Y_train_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_RF_Pred=clf_RF.predict(X_test)\n",
    "target_names=['0','1']\n",
    "print(classification_report(y_test, Y_test_RF_Pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.boxplot(x=analysis_df[\"useful\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(analysis_df))\n",
    "analysis_df['log_usefull']=np.log(analysis_df['useful']+1)\n",
    "print(analysis_df.dtypes)\n",
    "sns.distplot(analysis_df[\"log_usefull\"],bins=int(180/5),  hist=True, kde=True, color = 'darkblue', \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis_df['date'] =  pd.to_datetime(df_review['date']).dt.date\n",
    "#filtered_df = data_df[data_df['reviews_dateAdded_Date_time'].notnull()]\n",
    "#filtered_df = data_df[data_df['reviews_date_Date_time'].notnull()]\n",
    "#analysis_df['date']-dt.datetime.now().date()-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['diff_days'] = dt.datetime.now().date() - analysis_df['date']\n",
    "analysis_df['diff_days']=(analysis_df['diff_days']/np.timedelta64(1,'M'))\n",
    "\n",
    "\n",
    "analysis_df['usefull_diff'] = (analysis_df['useful']/analysis_df['diff_days'])\n",
    "analysis_df['usefull_diff'].describe()\n",
    "#usefull_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis_df['diff_days'] = dt.datetime.now().date() - analysis_df['date']\n",
    "analysis_df['diff_days']=(analysis_df['diff_days']/np.timedelta64(1,'M'))\n",
    "#(analysis_df['diff_days']/np.timedelta64(1,'M')).describe()\n",
    "corr_df = analysis_df.drop(['agg','log_usefull','usefull_diff','flesch_kincaid_grade','subjectivity'], axis=1)\n",
    "corr = abs(corr_df.corr())\n",
    "\n",
    "plt.figure(figsize= (10, 10))\n",
    "sns.heatmap(corr_df.corr())\n",
    "fig, ax = plt.subplots(figsize=(10, 10)) \n",
    "mask = np.zeros_like(corr_df.corr())\n",
    "\n",
    "mask[np.triu_indices_from(mask)] = 1\n",
    "sns.heatmap(corr_df.corr(), mask= mask, ax= ax, annot= True,annot_kws={\"size\": 11},fmt='.2f')\n",
    "\n",
    "\n",
    "corr = np.round(abs(corr_df.corr()),2)\n",
    "corr.style.background_gradient(cmap='coolwarm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis_df[['subjectivity','polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.array(analysis_df.drop(['usefull_bin','agg','useful','usefull_diff','date','subjectivity'], axis=1))\n",
    "#X= np.array(analysis_df['smog'])\n",
    "Y= np.array(analysis_df['usefull_diff'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.33, random_state=303)\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "X_test_scaled = preprocessing.scale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train_scaled, y_train)\n",
    "y_pred=reg.predict(X_test_scaled)\n",
    "#scaler.transform(X_test)\n",
    "(mean_squared_error(y_test, y_pred)**0.5)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X= np.array(analysis_df.drop(['usefull_bin','agg','useful','usefull_diff','date','log_usefull','subjectivity'], axis=1))\n",
    "#X= np.array(analysis_df['smog'])\n",
    "Y= np.array(analysis_df['log_usefull'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.33, random_state=303)\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "X_test_scaled = preprocessing.scale(X_test)\n",
    "reg = LinearRegression().fit(X_train_scaled, y_train)\n",
    "y_pred=reg.predict(X_test_scaled)\n",
    "#scaler.transform(X_test)\n",
    "print(r2_score(y_test, (np.exp(y_pred))))\n",
    "(mean_squared_error(y_test, (np.exp(y_pred)-1))**0.5)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis_df.to_csv(\"D:/Trinity_DS/Dissertations/201907/dataset_v2/analysis_df.csv\", index = None, header=True)\n",
    "clf_ridge = Ridge(alpha=100000)\n",
    "clf_ridge.fit(X_train_scaled, y_train) \n",
    "y_pred_0=clf_ridge.predict(X_train_scaled)\n",
    "#scaler.transform(X_test)\n",
    "mean_squared_error(y_train,np.exp(y_pred_0)-1)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf_ridge.predict(X_test_scaled)\n",
    "#scaler.transform(X_test)\n",
    "mean_squared_error(np.exp(y_pred)-1,y_test)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,(np.exp(y_pred)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((np.exp(y_pred))-1).mean())\n",
    "print(y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((sum((y_pred-y_test)**2))/len(y_pred))**0.5*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Politness Vs Helpfull and Polite vs Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.array(analysis_df['politness'])\n",
    "#X= np.array(analysis_df['smog'])\n",
    "Y= np.array(analysis_df['log_usefull'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.33, random_state=303)\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "X_test_scaled = preprocessing.scale(X_test)\n",
    "reg = LinearRegression().fit(X_train_scaled.reshape(-1, 1), y_train)\n",
    "y_pred=reg.predict(X_test_scaled.reshape(-1, 1))\n",
    "#scaler.transform(X_test)\n",
    "print(r2_score(y_test, (np.exp(y_pred))-1))\n",
    "(mean_squared_error(y_test, (np.exp(y_pred)-1))**0.5)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merged Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(analysis_df)\n",
    "review_roll_up_df=analysis_df.drop(['usefull_bin','date','diff_days'], axis=1)\n",
    "review_roll_up_df['user_id'] = df_review['user_id']\n",
    "#business_id\n",
    "review_roll_up_df['business_id'] = df_review['business_id']\n",
    "g1 = review_roll_up_df.groupby(['user_id','business_id']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "review_roll_up_df=g1.reset_index()\n",
    "join_review_user=pd.merge(df_user, review_roll_up_df,on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(join_review_user)\n",
    "join_review_user=join_review_user.drop([\n",
    "    'user_id',\n",
    " 'name',\n",
    " 'yelping_since',\n",
    " 'funny',\n",
    " 'cool',\n",
    " 'fans',\n",
    " 'compliment_hot',\n",
    " 'compliment_more',\n",
    " 'compliment_profile',\n",
    " 'compliment_cute',\n",
    " 'compliment_list',\n",
    " 'compliment_note',\n",
    " 'compliment_plain',\n",
    " 'compliment_cool',\n",
    " 'compliment_funny',\n",
    " 'compliment_writer',\n",
    " 'compliment_photos'\n",
    "], axis=1)\n",
    "g2 = join_review_user.groupby(['business_id']).sum()\n",
    "business_lvl_review_user=g2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_review_user=pd.merge(df_business.dropna(subset='business_id'),business_lvl_review_user.dropna(subset='business_id') ,on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(analysis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "join_review_user=pd.merge(df_user, review_roll_up_df1,on='user_id')\n",
    "list(join_review_user)\n",
    "join_review_user['business_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_final_df=pd.merge(df_business, join_review_user,on='business_id',how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()  # loads default word frequency list\n",
    "\n",
    "\n",
    "# if I just want to make sure some words are not flagged as misspelled\n",
    "spell.word_frequency.load_words(['microsoft', 'apple', 'google'])\n",
    "spell.known(['microsoft', 'google','asd'])  # will return both now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misspelled = spell.unknown(['something', 'is', 'hapenning', 'here'])\n",
    "len(misspelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
